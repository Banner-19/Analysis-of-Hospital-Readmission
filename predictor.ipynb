{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>n_lab_procedures</th>\n",
       "      <th>n_procedures</th>\n",
       "      <th>n_medications</th>\n",
       "      <th>n_outpatient</th>\n",
       "      <th>n_inpatient</th>\n",
       "      <th>n_emergency</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>glucose_test</th>\n",
       "      <th>A1Ctest</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetes_med</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[70-80)</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Circulatory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Other</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[70-80)</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[50-60)</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Circulatory</td>\n",
       "      <td>Circulatory</td>\n",
       "      <td>Circulatory</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[70-80)</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Circulatory</td>\n",
       "      <td>Other</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[60-70)</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>InternalMedicine</td>\n",
       "      <td>Other</td>\n",
       "      <td>Circulatory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  time_in_hospital  n_lab_procedures  n_procedures  n_medications  \\\n",
       "0  [70-80)                 8                72             1             18   \n",
       "1  [70-80)                 3                34             2             13   \n",
       "2  [50-60)                 5                45             0             18   \n",
       "3  [70-80)                 2                36             0             12   \n",
       "4  [60-70)                 1                42             0              7   \n",
       "\n",
       "   n_outpatient  n_inpatient  n_emergency medical_specialty       diag_1  \\\n",
       "0             2            0            0           Missing  Circulatory   \n",
       "1             0            0            0             Other        Other   \n",
       "2             0            0            0           Missing  Circulatory   \n",
       "3             1            0            0           Missing  Circulatory   \n",
       "4             0            0            0  InternalMedicine        Other   \n",
       "\n",
       "        diag_2       diag_3 glucose_test A1Ctest change diabetes_med  \\\n",
       "0  Respiratory        Other           no      no     no          yes   \n",
       "1        Other        Other           no      no     no          yes   \n",
       "2  Circulatory  Circulatory           no      no    yes          yes   \n",
       "3        Other     Diabetes           no      no    yes          yes   \n",
       "4  Circulatory  Respiratory           no      no     no          yes   \n",
       "\n",
       "  readmitted  \n",
       "0         no  \n",
       "1         no  \n",
       "2        yes  \n",
       "3        yes  \n",
       "4         no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"hospital_readmissions.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "time_in_hospital     0\n",
      "n_lab_procedures     0\n",
      "n_procedures         0\n",
      "n_medications        0\n",
      "n_outpatient         0\n",
      "n_inpatient          0\n",
      "n_emergency          0\n",
      "medical_specialty    0\n",
      "diag_1               0\n",
      "diag_2               0\n",
      "diag_3               0\n",
      "glucose_test         0\n",
      "A1Ctest              0\n",
      "change               0\n",
      "diabetes_med         0\n",
      "readmitted           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Example of filling missing values (customize based on your needs)\n",
    "data['medical_specialty'].fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using one-hot encoding or label encoding\n",
    "categorical_columns = ['age', 'medical_specialty', 'glucose_test', 'A1Ctest', 'change', 'diabetes_med', 'diag_1', 'diag_2', 'diag_3']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable 'readmitted' to numerical\n",
    "data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features if needed (e.g., interaction terms, derived metrics)\n",
    "# Example: Total visits\n",
    "data['total_visits'] = data['n_outpatient'] + data['n_inpatient'] + data['n_emergency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('readmitted', axis=1)  # Features\n",
    "y = data['readmitted']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.6166\n",
      "Precision: 0.6088069636456733\n",
      "Recall: 0.5076857386848848\n",
      "F1 Score: 0.5536670547147846\n",
      "ROC AUC Score: 0.6101257888307795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\bhaskar banerjee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\bhaskar banerjee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\bhaskar banerjee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bhaskar banerjee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bhaskar banerjee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 258.3/258.3 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Accuracy: 0.618\n",
      "Precision: 0.5969479353680431\n",
      "Recall: 0.5678906917164817\n",
      "F1 Score: 0.5820568927789934\n",
      "ROC AUC Score: 0.615021342848459\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the model with balanced data\n",
    "model = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize column names\n",
    "data.columns = data.columns.str.replace('[^A-Za-z0-9_]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 729 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n729 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1500, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 521, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 958, in _create_dmatrix\n    return QuantileDMatrix(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1529, in __init__\n    self._init(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1588, in _init\n    it.reraise()\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 576, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n    return fn()\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n    return self._handle_exception(lambda: self.next(input_data), 0)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n    input_data(**self.kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 633, in input_data\n    self.proxy.set_info(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 946, in set_info\n    self.feature_names = feature_names\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1322, in feature_names\n    raise ValueError(\nValueError: feature_names must be string, and may not contain [, ] or <\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m     18\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n\u001b[0;32m     24\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 729 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n729 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1500, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 521, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 958, in _create_dmatrix\n    return QuantileDMatrix(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1529, in __init__\n    self._init(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1588, in _init\n    it.reraise()\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 576, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n    return fn()\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n    return self._handle_exception(lambda: self.next(input_data), 0)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n    input_data(**self.kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 633, in input_data\n    self.proxy.set_info(\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 946, in set_info\n    self.feature_names = feature_names\n  File \"c:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1322, in feature_names\n    raise ValueError(\nValueError: feature_names must be string, and may not contain [, ] or <\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create an XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names must be string, and may not contain [, ] or <",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Train the XGBoost model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1500\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[1;32m-> 1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1520\u001b[0m     params,\n\u001b[0;32m   1521\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:521\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    502\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    503\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    518\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:958\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[0;32m    959\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, ref\u001b[38;5;241m=\u001b[39mref, nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m    960\u001b[0m         )\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1529\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1510\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         )\n\u001b[0;32m   1523\u001b[0m     ):\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1525\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1527\u001b[0m         )\n\u001b[1;32m-> 1529\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1588\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1576\u001b[0m config \u001b[38;5;241m=\u001b[39m make_jcargs(\n\u001b[0;32m   1577\u001b[0m     nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnthread, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m   1578\u001b[0m )\n\u001b[0;32m   1579\u001b[0m ret \u001b[38;5;241m=\u001b[39m _LIB\u001b[38;5;241m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[0;32m   1580\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1581\u001b[0m     it\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1586\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(handle),\n\u001b[0;32m   1587\u001b[0m )\n\u001b[1;32m-> 1588\u001b[0m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[0;32m   1590\u001b[0m _check_call(ret)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:576\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    574\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:557\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[1;34m(self, fn, dft_ret)\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:641\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_ref \u001b[38;5;241m=\u001b[39m ref\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\data.py:1280\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1280\u001b[0m input_data(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:633\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[1;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[0;32m    632\u001b[0m dispatch_proxy_set_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy, new, cat_codes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_host)\n\u001b[1;32m--> 633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mset_info(\n\u001b[0;32m    634\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m    635\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    637\u001b[0m )\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_ref \u001b[38;5;241m=\u001b[39m ref\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:946\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[1;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_float_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_upper_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m, label_upper_bound)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 946\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m \u001b[38;5;241m=\u001b[39m feature_names\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;241m=\u001b[39m feature_types\n",
      "File \u001b[1;32mc:\\Users\\Bhaskar Banerjee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1322\u001b[0m, in \u001b[0;36mDMatrix.feature_names\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;66;03m# prohibit the use symbols that may affect parsing. e.g. []<\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feature_names\n\u001b[0;32m   1321\u001b[0m ):\n\u001b[1;32m-> 1322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be string, and may not contain [, ] or <\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m feature_names_bytes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mbytes\u001b[39m(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feature_names]\n\u001b[0;32m   1327\u001b[0m c_feature_names \u001b[38;5;241m=\u001b[39m (ctypes\u001b[38;5;241m.\u001b[39mc_char_p \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(feature_names_bytes))(\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;241m*\u001b[39mfeature_names_bytes\n\u001b[0;32m   1329\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names must be string, and may not contain [, ] or <"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'hospital_readmissions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sanitize column names\n",
    "data.columns = data.columns.str.replace('[^A-Za-z0-9_]', '', regex=True)\n",
    "\n",
    "# Handle missing values\n",
    "data['medical_specialty'].fillna('Missing', inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding or label encoding\n",
    "categorical_columns = ['age', 'medical_specialty', 'glucose_test', 'A1Ctest', 'change', 'diabetes_med', 'diag_1', 'diag_2', 'diag_3']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Convert the target variable 'readmitted' to numerical\n",
    "data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop('readmitted', axis=1)  # Features\n",
    "y = data['readmitted']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 4s 6ms/step - loss: 0.6703 - accuracy: 0.5883 - val_loss: 0.6653 - val_accuracy: 0.5897\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6511 - accuracy: 0.6157 - val_loss: 0.6639 - val_accuracy: 0.5918\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.6430 - accuracy: 0.6304 - val_loss: 0.6637 - val_accuracy: 0.5900\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.6317 - val_loss: 0.6660 - val_accuracy: 0.6012\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.6314 - accuracy: 0.6359 - val_loss: 0.6660 - val_accuracy: 0.5897\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6266 - accuracy: 0.6460 - val_loss: 0.6726 - val_accuracy: 0.5947\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6218 - accuracy: 0.6526 - val_loss: 0.6745 - val_accuracy: 0.5910\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6172 - accuracy: 0.6550 - val_loss: 0.6763 - val_accuracy: 0.5938\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6114 - accuracy: 0.6590 - val_loss: 0.6791 - val_accuracy: 0.5932\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6067 - accuracy: 0.6684 - val_loss: 0.6802 - val_accuracy: 0.5938\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.6013 - accuracy: 0.6728 - val_loss: 0.6850 - val_accuracy: 0.5955\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5944 - accuracy: 0.6773 - val_loss: 0.6933 - val_accuracy: 0.5893\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5905 - accuracy: 0.6827 - val_loss: 0.6991 - val_accuracy: 0.5970\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5846 - accuracy: 0.6893 - val_loss: 0.7051 - val_accuracy: 0.5915\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5798 - accuracy: 0.6891 - val_loss: 0.7010 - val_accuracy: 0.5915\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5743 - accuracy: 0.6960 - val_loss: 0.7080 - val_accuracy: 0.5950\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5701 - accuracy: 0.6994 - val_loss: 0.7159 - val_accuracy: 0.5870\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5638 - accuracy: 0.7021 - val_loss: 0.7192 - val_accuracy: 0.5788\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5610 - accuracy: 0.7038 - val_loss: 0.7297 - val_accuracy: 0.5897\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5542 - accuracy: 0.7071 - val_loss: 0.7329 - val_accuracy: 0.5880\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5502 - accuracy: 0.7122 - val_loss: 0.7524 - val_accuracy: 0.5753\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5472 - accuracy: 0.7174 - val_loss: 0.7452 - val_accuracy: 0.5888\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5433 - accuracy: 0.7194 - val_loss: 0.7449 - val_accuracy: 0.5807\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5377 - accuracy: 0.7216 - val_loss: 0.7552 - val_accuracy: 0.5805\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5353 - accuracy: 0.7259 - val_loss: 0.7670 - val_accuracy: 0.5745\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5314 - accuracy: 0.7308 - val_loss: 0.7779 - val_accuracy: 0.5698\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5285 - accuracy: 0.7297 - val_loss: 0.7807 - val_accuracy: 0.5757\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5235 - accuracy: 0.7347 - val_loss: 0.7849 - val_accuracy: 0.5872\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.5225 - accuracy: 0.7355 - val_loss: 0.7944 - val_accuracy: 0.5775\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5169 - accuracy: 0.7431 - val_loss: 0.7904 - val_accuracy: 0.5765\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5131 - accuracy: 0.7431 - val_loss: 0.8104 - val_accuracy: 0.5788\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5129 - accuracy: 0.7419 - val_loss: 0.8008 - val_accuracy: 0.5792\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5080 - accuracy: 0.7459 - val_loss: 0.8181 - val_accuracy: 0.5715\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5061 - accuracy: 0.7466 - val_loss: 0.8350 - val_accuracy: 0.5707\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.5022 - accuracy: 0.7464 - val_loss: 0.8232 - val_accuracy: 0.5727\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4994 - accuracy: 0.7521 - val_loss: 0.8298 - val_accuracy: 0.5765\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4974 - accuracy: 0.7533 - val_loss: 0.8400 - val_accuracy: 0.5710\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4916 - accuracy: 0.7574 - val_loss: 0.8449 - val_accuracy: 0.5750\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4917 - accuracy: 0.7546 - val_loss: 0.8558 - val_accuracy: 0.5730\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4874 - accuracy: 0.7621 - val_loss: 0.8635 - val_accuracy: 0.5760\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4871 - accuracy: 0.7600 - val_loss: 0.8619 - val_accuracy: 0.5727\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4827 - accuracy: 0.7642 - val_loss: 0.8779 - val_accuracy: 0.5623\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4806 - accuracy: 0.7662 - val_loss: 0.8799 - val_accuracy: 0.5735\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.7666 - val_loss: 0.8871 - val_accuracy: 0.5610\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4768 - accuracy: 0.7663 - val_loss: 0.8874 - val_accuracy: 0.5650\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4740 - accuracy: 0.7677 - val_loss: 0.9047 - val_accuracy: 0.5705\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4731 - accuracy: 0.7669 - val_loss: 0.9054 - val_accuracy: 0.5680\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4706 - accuracy: 0.7710 - val_loss: 0.9128 - val_accuracy: 0.5707\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4691 - accuracy: 0.7729 - val_loss: 0.9102 - val_accuracy: 0.5665\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.4688 - accuracy: 0.7709 - val_loss: 0.9230 - val_accuracy: 0.5642\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "Accuracy: 0.577\n",
      "Precision: 0.5574683544303798\n",
      "Recall: 0.4701110162254483\n",
      "F1 Score: 0.5100764419735928\n",
      "ROC AUC Score: 0.5934071706573263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'hospital_readmissions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sanitize column names\n",
    "data.columns = data.columns.str.replace('[^A-Za-z0-9_]', '', regex=True)\n",
    "\n",
    "# Handle missing values\n",
    "data['medical_specialty'].fillna('Missing', inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding or label encoding\n",
    "categorical_columns = ['age', 'medical_specialty', 'glucose_test', 'A1Ctest', 'change', 'diabetes_med', 'diag_1', 'diag_2', 'diag_3']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Convert the target variable 'readmitted' to numerical\n",
    "data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Ensure all column names are valid\n",
    "valid_column_names = {col: col.replace('<', '').replace('>', '').replace('[', '').replace(']', '').replace('{', '').replace('}', '') for col in data.columns}\n",
    "data.rename(columns=valid_column_names, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop('readmitted', axis=1)  # Features\n",
    "y = data['readmitted']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Train the AdaBoost model\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = adaboost_model.predict(X_test)\n",
    "y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6132\n",
      "Precision: 0.6167048054919908\n",
      "Recall: 0.46029035012809566\n",
      "F1 Score: 0.5271393643031785\n",
      "ROC AUC Score: 0.6491910247587324\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'hospital_readmissions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sanitize column names\n",
    "data.columns = data.columns.str.replace('[^A-Za-z0-9_]', '', regex=True)\n",
    "\n",
    "# Handle missing values\n",
    "data['medical_specialty'].fillna('Missing', inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding or label encoding\n",
    "categorical_columns = ['age', 'medical_specialty', 'glucose_test', 'A1Ctest', 'change', 'diabetes_med', 'diag_1', 'diag_2', 'diag_3']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Convert the target variable 'readmitted' to numerical\n",
    "data['readmitted'] = data['readmitted'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Ensure all column names are valid\n",
    "valid_column_names = {col: col.replace('<', '').replace('>', '').replace('[', '').replace(']', '').replace('{', '').replace('}', '') for col in data.columns}\n",
    "data.rename(columns=valid_column_names, inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('readmitted', axis=1)  # Features\n",
    "y = data['readmitted']  # Target variable\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'SVM': SVC(probability=True)\n",
    "}\n",
    "\n",
    "# Function to evaluate the models\n",
    "def evaluate_model(model, X, y):\n",
    "    accuracy = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X, y, cv=5, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X, y, cv=5, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X, y, cv=5, scoring='f1').mean()\n",
    "    roc_auc = cross_val_score(model, X, y, cv=5, scoring='roc_auc').mean()\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# Evaluate each model and store the results\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    accuracy, precision, recall, f1, roc_auc = evaluate_model(model, X_scaled, y)\n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.609\n",
      "Precision: 0.5971873430436966\n",
      "Recall: 0.5076857386848848\n",
      "F1 Score: 0.5488114470343873\n",
      "ROC AUC Score: 0.6029775570775816\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Feature  Importance\n",
      "1                           n_lab_procedures    0.150624\n",
      "3                              n_medications    0.131824\n",
      "0                           time_in_hospital    0.094116\n",
      "2                               n_procedures    0.060463\n",
      "45                              total_visits    0.047161\n",
      "5                                n_inpatient    0.034965\n",
      "43                              diag_3_Other    0.025746\n",
      "36                              diag_2_Other    0.025428\n",
      "22                                change_yes    0.021304\n",
      "29                              diag_1_Other    0.020992\n",
      "15                 medical_specialty_Missing    0.019920\n",
      "4                               n_outpatient    0.019004\n",
      "9                                age_[70-80)    0.018845\n",
      "8                                age_[60-70)    0.018691\n",
      "38                           diag_3_Diabetes    0.018685\n",
      "30                        diag_1_Respiratory    0.017319\n",
      "20                                A1Ctest_no    0.016706\n",
      "31                           diag_2_Diabetes    0.015448\n",
      "37                        diag_2_Respiratory    0.015422\n",
      "10                               age_[80-90)    0.015288\n",
      "7                                age_[50-60)    0.014365\n",
      "23                          diabetes_med_yes    0.014272\n",
      "6                                n_emergency    0.014055\n",
      "14        medical_specialty_InternalMedicine    0.013368\n",
      "44                        diag_3_Respiratory    0.013089\n",
      "25                          diag_1_Digestive    0.013087\n",
      "26                             diag_1_Injury    0.010526\n",
      "24                           diag_1_Diabetes    0.010523\n",
      "13  medical_specialty_Family/GeneralPractice    0.010514\n",
      "12        medical_specialty_Emergency/Trauma    0.010439\n",
      "16                   medical_specialty_Other    0.010022\n",
      "18                           glucose_test_no    0.008266\n",
      "32                          diag_2_Digestive    0.007956\n",
      "28                    diag_1_Musculoskeletal    0.007544\n",
      "39                          diag_3_Digestive    0.007400\n",
      "17                 medical_specialty_Surgery    0.007115\n",
      "21                            A1Ctest_normal    0.007107\n",
      "11                              age_[90-100)    0.006405\n",
      "33                             diag_2_Injury    0.005444\n",
      "42                    diag_3_Musculoskeletal    0.004767\n",
      "40                             diag_3_Injury    0.004699\n",
      "19                       glucose_test_normal    0.004561\n",
      "35                    diag_2_Musculoskeletal    0.004066\n",
      "41                            diag_3_Missing    0.001856\n",
      "34                            diag_2_Missing    0.000471\n",
      "27                            diag_1_Missing    0.000128\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
